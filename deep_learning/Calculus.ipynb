{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4a1a4",
   "metadata": {},
   "source": [
    "# Calculus and Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513065a",
   "metadata": {},
   "source": [
    "In deep learning, we typically choose **loss functions** that are **differentiable** with respect to our modelʼs parameters. Put simply, this means that for each parameter, we can determine how rapidly the loss would increase or decrease, were we to increase or decrease that parameter by an infinitesimally small amount.\n",
    "\n",
    "1. Getting better on training datasets means minimizing a loss function. \n",
    "2. Producing a model that performs well on data that we have never seen before, that means what's performance of the model on testing dataset.\n",
    "\n",
    "Thus we can decompose the task of fitting models into two key concerns:\n",
    "1. **optimization**:  the process of fitting our models to observed data (like training and valid datasets)\n",
    "2. **Generalization**: produce models whose validity extends beyond the exact set of data examples used to train them, like testing datasets\n",
    "\n",
    "Suppose that we have a deep neural network where the weights are $w=(w_1, w_2, \\ldots, w_n)$. Given a training dataset, we consider to minimize the loss of our neural network on this dataset: $\\mathcal{L}(w)$:\n",
    "\n",
    "**Solution**: \n",
    "1. we often start by initializing our weights randomly. \n",
    "2. We iteratively take small steps in the direction which makes the loss decrease as rapidly as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39768371",
   "metadata": {},
   "source": [
    "# Differential Calculus (微分)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71392b3",
   "metadata": {},
   "source": [
    "## Derivative(导数) of a function\n",
    "\n",
    "Suppose that we have a function ($y=f(x)$) $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, whose input and output are both scalars. The **derivative** of f is defined as:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "f^{'}(x) &= \\lim_{h \\rightarrow 0} \\frac{f(x+h) - f(x)}{h} = \\lim_{\\Delta_x \\rightarrow 0} \\frac{f(x+\\Delta_x) -f(x)}{\\Delta_x}\\;\\textrm{if this limit exists} \\\\\n",
    "&=\\frac{dy}{dx} = \\frac{df}{dx} = \\frac{d}{dx}f(x) = Df(x) = D_xf(x)\n",
    "\\end{aligned}\n",
    "\\end{equation} where symbols $\\frac{d}{dx}$ and $D$ are **differentiation** operators that indicate operation of differentiation.\n",
    "\n",
    "If $f^{'}(a)$ exists, $f$ is said to be **differentiable** at $a$, that is defined as:\n",
    "\\begin{equation}\n",
    "f^{'}(a) = \\lim_{x \\rightarrow a} \\frac{f(x) - f(a)}{x-a}\n",
    "\\end{equation}\n",
    "\n",
    "If $f$ is **differentiable** at every number of an interval ($x\\in [a,b]$), then this function is differentiable on this interval ($[a,b]$).\n",
    "\n",
    "## Linear Approximation\n",
    "\n",
    "In particular, note that the following equation approximates the value of f by a line which passes through the point (x, f(x)) and has slope $f'$. In this way we say that the derivative gives a linear approximation to the function f.\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{df(x)}{dx} = \\lim_{\\epsilon \\rightarrow 0} \\frac{f(x+\\epsilon) - f(x))}{\\epsilon } &\\Rightarrow \\frac{df(x)}{dx} \\approx \\frac{f(x+\\epsilon) - f(x))} {\\epsilon } \\\\\n",
    "\\Rightarrow \\epsilon \\frac{df(x)}{dx} \\approx f(x+\\epsilon) - f(x) \\\\\n",
    "\\Rightarrow f(x+\\epsilon) \\approx f(x) + \\epsilon \\frac{df(x)}{dx} = f(x) + \\epsilon f^{'}\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db64ad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=0.00010, numerical limit=2.00030\n",
      "h=0.00001, numerical limit=2.00003\n",
      "h=0.00000, numerical limit=2.00000\n",
      "h=0.00000, numerical limit=2.00000\n",
      "h=0.00000, numerical limit=2.00000\n"
     ]
    }
   ],
   "source": [
    "# f(x) = 3x^2 - 4x\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x\n",
    "\n",
    "# Functions to calcuate limits\n",
    "def numerical_limit(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "h = 0.0001\n",
    "x= 1\n",
    "for i in range(5):\n",
    "    print(f'h={h:.5f}, numerical limit={numerical_limit(f, x, h):.5f}')\n",
    "    h *= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052790c",
   "metadata": {},
   "source": [
    "## Common Derivatives\n",
    "\n",
    "- $(x^n)' = nx^{n-1}$ (the power rule, $n$ is any real number)\n",
    "- $(e^x)' = e^x$\n",
    "- $(\\sin(x))' = \\cos(x)$\n",
    "- $(\\cos(x))' = -\\sin(x)$\n",
    "- $\\tan(x)' = \\sec^2(x)$\n",
    "- $\\cot(x)' = -\\csc^2(x)$\n",
    "- $\\sec(x)' = \\sec x \\tan x$\n",
    "- $\\csc x' = -\\csc x \\cot x$\n",
    "- $(a^x)' = a^x\\ln x (a \\gt 0, a \\neq 1)$\n",
    "- $(\\log_ax)' = \\frac{1}{x\\ln a} (a \\gt 0, a \\neq 1)$\n",
    "- $(\\ln(x))' = \\frac{1}{x}$\n",
    "\n",
    "## Derivative Rules\n",
    "\n",
    "Assume $u=u(x), v=v(x)$ are differentiable at an interval $x \\in [a,b]$, and $C$ is a constant number\n",
    "1. Constant Multiple Rule: (Cu)^' = Cu'\n",
    "2. Sum Rule: $(u \\pm v) = u' \\pm v'$\n",
    "3. Product Rule $(uv)' = u'v + uv'$\n",
    "4. Quotient Rule: $(\\frac{u}{v})' = \\frac{u'v - uv'}{v^2} \\; (v \\neq 0 )$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaaffb0",
   "metadata": {},
   "source": [
    "## Partial Derivatives\n",
    "\n",
    "So far we have dealt with the differentiation of functions with just **one variable**. In deep learning, functions often depend on **many variables**. Thus, we need to extend the ideas of differentiation to these **multivariate functions**.\n",
    "\n",
    "Let $y = f(x_1, x_2, \\ldots, x_n)$ be a function with $n$ variables. The partial derivative of $y$ with respect to its $i^{th}$ parameter $x_i$ is:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial f}{\\partial x_i} = f_{x_i} = f_i = D_if = D_{x_i} f = \\lim_{\\epsilon \\rightarrow 0} \\frac{f(x_1, x_2, \\ldots, x_i + \\epsilon, \\ldots, x_n) - f(x_1, x_2, \\ldots, x_i, \\ldots, x_n)}{\\epsilon}\n",
    "\\end{equation}\n",
    "\n",
    "To calculate $\\frac{\\partial y}{\\partial x_i}$, we can simply treat all variables except $x_i$ as constants and calculate the derivative of $y$ with respect to $x_i$. \n",
    "\n",
    "\\begin{equation}\n",
    "f(x+\\epsilon) \\approx f(x) + \\epsilon  \\frac{df}{dx}(x) \\\\ \\Downarrow \\\\\n",
    "L(x_1 + \\epsilon_1, x_2, \\ldots, x_n) \\approx L(x_1, x_2, \\ldots, x_n) + \\epsilon_1 \\frac{\\partial L}{\\partial x_1} (x_1, x_2, \\ldots, x_n) \\\\ \\Downarrow \\\\\n",
    "L(x_1 + \\epsilon_1, x_2 + \\epsilon_2, \\ldots, x_n + \\epsilon_n) \\approx L(x_1, x_2, \\ldots, x_n) + \\sum_{i=1}^{n} \\epsilon_i \\frac{\\partial L}{\\partial x_i} (x_1, x_2, \\ldots, x_n) \n",
    "\\end{equation}\n",
    "\n",
    "This may look like a mess, but we can make this more familiar by noting that the sum on the right looks exactly like a dot product, so if we let:\n",
    "\n",
    "\\begin{equation}\n",
    "\\epsilon = [\\epsilon_1, \\ldots, \\epsilon_n]^T \\; \\textrm{and} \\; \\Delta_x L = [\\frac{\\partial L}{\\partial x_1}, \\ldots, \\frac{\\partial L}{\\partial x_n}]  \\\\ \\Downarrow \\\\\n",
    "L(X + \\epsilon) \\approx L(X) + \\epsilon \\cdot \\Delta_x L(X)\n",
    "\\end{equation}\n",
    "We will call the vector $\\Delta_x L$ the gradient of $L$. This equation allows us to tell approximately how the function L will change given any perturbation to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50975ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'approximation: tensor([1.0819]), true Value: tensor([1.0821])'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython import display\n",
    "def f(x, y):\n",
    "    return torch.log(torch.exp(x) + torch.exp(y))\n",
    "def grad_f(x, y):\n",
    "    return torch.tensor([torch.exp(x) / (torch.exp(x) + torch.exp(y)), torch.exp(y) / (torch.exp(x) + torch.exp(y))])\n",
    "\n",
    "epsilon = torch.tensor([0.01, -0.03])\n",
    "\n",
    "grad_approx = f(torch.tensor([0.]), torch.log(torch.tensor([2.]))) + epsilon.dot(grad_f(torch.tensor([0.]), torch.log(torch.tensor(2.))))\n",
    "\n",
    "true_value = f(torch.tensor([0.]) + epsilon[0], torch.log(torch.tensor([2.])) + epsilon[1])\n",
    "\n",
    "f'approximation: {grad_approx}, true Value: {true_value}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100fa14",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "\n",
    "We can concatenate partial derivatives of a multivariate function with respect to all its variables to obtain the **gradient** vector of the function\n",
    "\n",
    "Suppose that the input of function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is an n-dimensional vector $x = [x_1, x_n, \\ldots, x_n]^T$ and the output is a scalar. The gradient of the function $f(x)$ with respect to $x$ is a vector of n partial derivatives:\n",
    "\\begin{equation}\n",
    "\\Delta_xf(x) = \\Delta f(x) = [\\frac{\\partial y}{\\partial x_1}, \\frac{\\partial y}{\\partial x_2}, \\ldots, \\frac{\\partial y}{\\partial x_n}]^T  = [\\frac{\\partial f(x)}{\\partial x_1}, \\frac{\\partial f(x)}{\\partial x_2}, \\ldots, \\frac{\\partial f(x)}{\\partial x_n}]^T\n",
    "\\end{equation}\n",
    "\n",
    "Let x be an n-dimensional vector $x = [x_1, x_n, \\ldots, x_n]^T$, The following rules are often used when differentiating multivariate functions:\n",
    "\n",
    "- For all $A \\in \\mathbb{R}^{m \\times n}$, $\\Delta_x A x = A^T$\n",
    "- For all $A \\in \\mathbb{R}^{n \\times m}$, $\\Delta_x x^T A = A$\n",
    "- For all $A \\in \\mathbb{R}^{n \\times n}$, $\\Delta_x x^T A x = (A + A^T) x$\n",
    "- $\\Delta_x ||x||^2 = \\Delta_x x^T x = 2x$\n",
    "- $\\forall X, \\Delta_X ||X||^2_F = \\Delta_x x^T x = 2X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f2187",
   "metadata": {},
   "source": [
    "## Geometry of Gradients and Gradient Descent\n",
    "Consider an input vecotr $X=[x_1, \\ldots, x_n]$ and its corresponding loss function $L(X)$, $L$ can be approxmated and minimized by following equation:\n",
    "\\begin{equation}\n",
    "L(X + \\epsilon) \\approx L(X) + \\epsilon \\cdot \\Delta_x L(X)\n",
    "\\end{equation} \n",
    "where $\\epsilon = [\\epsilon_1, \\ldots, \\epsilon_n]^T$ and gradients $\\Delta_x L = [\\frac{\\partial L}{\\partial x_1}, \\ldots, \\frac{\\partial L}{\\partial x_n}]$.\n",
    "\n",
    "Let us suppose that I want to use this to help minimize our loss L. Let us understand geometrically the algorithm of gradient descent first:\n",
    "\n",
    "1. Start with a random choice for the initial parameters $X$\n",
    "2. Find the direction $v$ that makes $L$ decrease the most rapidly at $X$.\n",
    "3. Take a small step in that direction: $X \\rightarrow X + \\epsilon v$\n",
    "4. Repeat\n",
    "\n",
    "The only thing we do not know exactly how to do is to compute the vector $v$ in the second step. We will call such a direction **the direction of steepest descent**.\n",
    "\n",
    "Using the geometric understanding of dot products $\\cos(\\theta) = \\frac{u \\cdot v}{ ||u||*||v||}$ where $\\theta$ is the angle between two vectors $u$ and $v$, we can rewrite the above equation as:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "L(X + v) {}&\\approx L(X) + v \\cdot \\Delta_x L(X) \\\\\n",
    "&= L(X) + ||v|| * || \\Delta_x L(X)|| \\cos(\\theta) \\\\\n",
    "&= L(X) + || \\Delta_x L(X)|| \\cos(\\theta)\n",
    "\\end{aligned}\n",
    "\\end{equation} Note that we have taken our direction to have length one for convenience, and used $\\theta$ for the angle\n",
    "between $v$ and $\\Delta_XL(X)$.\n",
    "\n",
    "Intuitively, we want to find the direction that decreases L as rapidly as possible, that means $L(X + v) - L(X) = || \\Delta_x L(X)|| \\cos(\\theta) \\leq 0$. Therefore, the only way the direction we pick enters into this equation is through $\\cos(\\theta)$, and thus we wish to make this cosine as negative as possible. Now, recalling the shape of cosine, we can make this as negative as possible by making $\\cos(\\theta) = -1$ or equivalently making the angle between the gradient and our chosen direction to be $\\pi$ radians or equivalently 180 degrees. \n",
    "- The only way to achieve this is to head in the exact opposite direction: pick $v$ to point in the exact opposite direction to $\\Delta_XL(X)$.\n",
    "- That means the direction of steepest decent points in the direction of $-\\Delta_XL(X)$.\n",
    "\n",
    "Thus our informal algorithm can be rewritten as follows.\n",
    "\n",
    "1. Start with a random choice for the initial parameters $X$\n",
    "2. Find the direction $v$ that makes $L$ decrease the most rapidly at $X$, that's $v = -\\Delta_XL(X)$.\n",
    "3. Take a small step in the opposite of that direction: $X \\rightarrow X - \\epsilon \\Delta_XL(X)$\n",
    "4. Repeat\n",
    "\n",
    "**Summary**\n",
    "\n",
    " - Use the gradient to find the direction that decreases the loss as rapidly as possible, and update the parameters to take a step in that direction\n",
    " - The only possible points where we can minimize (or maximize) a function will have gradient equal to zero, however, not every point with gradient zero is the true global minimum (or maximum)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d394066",
   "metadata": {},
   "source": [
    "## Multivariate Chain Rule\n",
    "\n",
    "The chain rule enables us to differentiate composite functions. \n",
    "\n",
    "Let us first consider functions of a single variable. Suppose that functions $y = f(u)$ and $u = g(x)$ are both differentiable, then the chain rule states that:\n",
    "\\begin{equation}\n",
    "\\frac{dy}{dx} = \\frac{dy}{du}*\\frac{du}{dx}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Next, suppose that the differentiable function y has variables $y = f(x_1, x_2, \\ldots, x_n) = f(u_1, u_2, \\ldots, u_m)$, where each differentiable function $u_i = g_i(x_1, x_2, \\ldots, x_n)$. Then the chain rule gives for a variable $x_i$:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{dy}{d{x_i}} &= \\sum_{j = 1}^m \\frac{dy}{d{u_j}}*\\frac{d{u_j}}{d{x_i}}\\\\\n",
    "&=\\frac{dy}{d{u_1}}*\\frac{d{u_1}}{d{x_i}} + \\frac{dy}{d{u_2}}*\\frac{d{u_2}}{d{x_i}} + \\ldots + \\frac{dy}{d{u_m}}*\\frac{d{u_m}}{d{x_i}}\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b59b06",
   "metadata": {},
   "source": [
    "### Example\n",
    "Let us suppose that we have a function of four variables $(w, x, y$ and $z)$, as shown in following figure\n",
    "![The function relations above where nodes represent values and edges show functional dependence](images/calculus_chain_1.png)\n",
    "\n",
    "we can make by composing many terms:\n",
    "\\begin{equation}\n",
    "y = f(u, v) = (u + v)^2 \\\\\n",
    "u = u(a, b) = (a + b)^2, \\; v = v(a,b) = (a - b)^2 \\\\\n",
    "a = a(w, x, y, z) = (w +x + y + z)^2, b = b(w, x, y, z) = (w + x - y - z)^2\n",
    "\\end{equation}\n",
    "\n",
    "Such chains of equations are common when working with neural networks, so trying to understand how to compute gradients of such functions is key.\n",
    "\n",
    "If we want to compute say $\\frac{\\partial f}{\\partial w}$, we may apply the multi-variate chain rule to see:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial w} = \\frac{\\partial f}{\\partial u}\\frac{\\partial u}{\\partial w} + \\frac{\\partial f}{\\partial v}\\frac{\\partial v}{\\partial w} \\\\\n",
    "\\frac{\\partial u}{\\partial w} = \\frac{\\partial u}{\\partial a}\\frac{\\partial a}{\\partial w} + \\frac{\\partial u}{\\partial b}\\frac{\\partial b}{\\partial w} \\\\\n",
    "\\frac{\\partial v}{\\partial w} = \\frac{\\partial v}{\\partial a}\\frac{\\partial a}{\\partial w} + \\frac{\\partial v}{\\partial b}\\frac{\\partial b}{\\partial w} \\\\\n",
    "\\end{equation}\n",
    "\n",
    "Let us try using this decomposition to compute $\\frac{\\partial f}{\\partial w}$. Notice that all we need here are the various single step partials:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial u} = 2(u+v), \\frac{\\partial f}{\\partial v} = 2(u+v) \\\\\n",
    "\\frac{\\partial u}{\\partial a} = 2(a+b), \\frac{\\partial u}{\\partial b} = 2(a+b) \\\\\n",
    "\\frac{\\partial v}{\\partial a} = 2(a-b), \\frac{\\partial v}{\\partial b} = -2(a+b) \\\\\n",
    "\\frac{\\partial a}{\\partial w} = 2(w+x+y+z), \\frac{\\partial b}{\\partial w} = 2(w+x-y-z)\n",
    "\\end{equation}\n",
    "\n",
    "If we write this out into code this becomes a fairly manageable expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0b0340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f at -1, 0, -2, 1 is 1024\n"
     ]
    }
   ],
   "source": [
    "# Compute the value of the function from inputs to outputs\n",
    "w, x, y, z = -1, 0, -2, 1\n",
    "a, b = (w + x + y + z)**2, (w + x - y - z)**2\n",
    "u, v = (a + b)**2, (a - b)**2\n",
    "f = (u + v)**2\n",
    "print(f' f at {w}, {x}, {y}, {z} is {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d999ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dw at -1, 0, -2, 1 is -4096\n"
     ]
    }
   ],
   "source": [
    "# Compute the single step partials\n",
    "df_du, df_dv = 2 * (u + v), 2 * (u + v)\n",
    "du_da, du_db = 2 * (a + b), 2 * (a + b)\n",
    "dv_da, dv_db = 2 * (a - b), -2 * (a -b)\n",
    "\n",
    "da_dw, db_dw = 2 * (w + x + y + z), 2 * (w + x - y - z)\n",
    "da_dx, db_dx = 2 * (w + x + y + z), 2 * (w + x - y - z)\n",
    "da_dy, db_dy = 2 * (w + x + y + z), -2 * (w + x - y - z)\n",
    "da_dz, db_dz = 2 * (w + x + y + z), -2 * (w + x - y - z)\n",
    "\n",
    "# Compute the final result from inputs to outputs\n",
    "du_dw = du_da * da_dw + du_db * db_dw \n",
    "dv_dw = dv_da * da_dw + dv_db * db_dw\n",
    "df_dw = df_du * du_dw + df_dv * dv_dw\n",
    "\n",
    "print(f'df/dw at {w}, {x}, {y}, {z} is {df_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fc1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dw at -1, 0, -2, 1 is -4096\n",
      "df/dx at -1, 0, -2, 1 is -4096\n",
      "df/dy at -1, 0, -2, 1 is -4096\n",
      "df/dz at -1, 0, -2, 1 is -4096\n"
     ]
    }
   ],
   "source": [
    "# Now compute how f changes when we change any value from output to input\n",
    "df_da = df_du * du_da + df_dv * dv_da\n",
    "df_db = df_du * du_db + df_dv * dv_db\n",
    "\n",
    "df_dw = df_da * da_dw + df_db * db_dw\n",
    "df_dx = df_da * da_dx + df_db * db_dx\n",
    "df_dy = df_da * da_dy + df_db * db_dy \n",
    "df_dz = df_da * da_dz + df_db * db_dz\n",
    "\n",
    "print(f'df/dw at {w}, {x}, {y}, {z} is {df_dw}')\n",
    "print(f'df/dx at {w}, {x}, {y}, {z} is {df_dx}')\n",
    "print(f'df/dy at {w}, {x}, {y}, {z} is {df_dy}')\n",
    "print(f'df/dz at {w}, {x}, {y}, {z} is {df_dz}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a338a",
   "metadata": {},
   "source": [
    "The fact that we compute derivatives from f back towards the inputs rather than from the inputs forward to the outputs (as we did in the first code snippet above) is what gives this algorithm its name: **backpropagation**. Note that there are two steps: \n",
    "1. Compute the value of the function, and the single step partials from front to back. While not done above, this can be combined into a single forward pass. \n",
    "2. Compute the gradient of f from back to front. We call this the backwards pass.\n",
    "\n",
    "\n",
    "This is precisely what every deep learning algorithm implements to allow the computation of the gradient of the loss with respect to every weight in the network at one pass. It is an astonishing fact that we have such a decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b146a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f: tensor([1024.], grad_fn=<PowBackward0>) at \n",
      " w: tensor([-1.], requires_grad=True), \n",
      " x: tensor([0.], requires_grad=True), \n",
      " y: tensor([-2.], requires_grad=True), \n",
      " z: tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize as ndarrays, then attach gradients\n",
    "w = torch.tensor([-1.], requires_grad=True)\n",
    "x = torch.tensor([0.], requires_grad=True)\n",
    "y = torch.tensor([-2.], requires_grad=True)\n",
    "z = torch.tensor([1.], requires_grad=True)\n",
    "# Do the computation like usual, tracking gradients\n",
    "a, b = (w + x + y + z)**2, (w + x - y - z)**2\n",
    "u, v = (a + b)**2, (a - b)**2\n",
    "f = (u + v)**2\n",
    "print(f' f: {f} at \\n w: {w}, \\n x: {x}, \\n y: {y}, \\n z: {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65da7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dw at -1.0, 0.0, -2.0, 1.0 is -4096.0\n",
      "df/dx at -1.0, 0.0, -2.0, 1.0 is -4096.0\n",
      "df/dy at -1.0, 0.0, -2.0, 1.0 is -4096.0\n",
      "df/dz at -1.0, 0.0, -2.0, 1.0 is -4096.0\n"
     ]
    }
   ],
   "source": [
    "# Execute backward pass\n",
    "#All of what we did above can be done automatically by calling f.backwards().\n",
    "f.backward()\n",
    "\n",
    "print(f'df/dw at {w.data.item()}, {x.data.item()}, {y.data.item()}, '\n",
    "      f'{z.data.item()} is {w.grad.data.item()}')\n",
    "print(f'df/dx at {w.data.item()}, {x.data.item()}, {y.data.item()}, '\n",
    "      f'{z.data.item()} is {x.grad.data.item()}')\n",
    "print(f'df/dy at {w.data.item()}, {x.data.item()}, {y.data.item()}, '\n",
    "      f'{z.data.item()} is {y.grad.data.item()}')\n",
    "print(f'df/dz at {w.data.item()}, {x.data.item()}, {y.data.item()}, '\n",
    "      f'{z.data.item()} is {z.grad.data.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882ff0e",
   "metadata": {},
   "source": [
    "## How to calucate differentiation in Pytorch: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa8433",
   "metadata": {},
   "source": [
    "### Backward for a scalar variable returned value y\n",
    "\n",
    "Suppose a differentiating function $y = f(x) = 2*x^T*x$ where $x$ is a n-dimensional vectors:\n",
    "\n",
    "\\begin{equation}\n",
    "y = f(x) = 2*x^T*x = 2 (x^2_1 + x^2_2 + \\ldots + x^2_n)\n",
    "\\end{equation}\n",
    "\n",
    "The gradients of this function is: \n",
    "\\begin{equation}\n",
    "\\Delta_x f(x) = [\\frac{\\partial y}{\\partial x_1}, \\frac{\\partial y}{\\partial x_2}, \\ldots, \\frac{\\partial y}{\\partial x_n}]^T = [4x_1, 4x_2, \\ldots, 4x_n]^T\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a55feb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# A differentiating function f(x) = 2X^T * X with a scalar value returned\n",
    "def f(x):\n",
    "    return 2*torch.dot(x, x)\n",
    "\n",
    "# let us create the variable x and assign it an initial value\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096c4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important that we do not allocate new memory every time we take a derivative with respect \n",
    "# to a parameter because we will often update the same parameters thousands or millions of times and\n",
    "# could quickly run out of memory.\n",
    "# The fact that gradients need to be computed for a Tensor do not mean that the grad attribute will be populated\n",
    "x.requires_grad_(True) # Same as `x = torch.arange(4.0, requires_grad=True)`\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82de0be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us calculate y.\n",
    "# Since x is a vector of length 4, an dot product of x and x is performed, yielding the scalar output that we assign to y.\n",
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e33415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this time, there is no gradients are calcuated for x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e12b3f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we can automatically calculate the gradient of y with respect to each\n",
    "# component of x by calling the function for backpropagation and printing the gradient.\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01cfcfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The gradient of the function y = 2x^⊤*x with respect to x should be 4x.\n",
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c2fe282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch accumulates the gradient in default, we need to clear the previous values\n",
    "x.grad.zero_()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac82ace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us calculate another function of y = sum(x) = x_1 + x_n + ... + x_n.\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc36bc1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Backward for Non-Scalar returned Variables Y\n",
    "\n",
    "The most natural interpretation of the differentiation of a vector y with respect to a vector x is a matrix. For higher-order and higher-dimensional y and x, the differentiation result could be a high-order tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "470635fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "The output Y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
      "The x grad: tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# A differentiating function f(x) = 2X^T * X with a scalar value returned\n",
    "def f(x):\n",
    "    return x * x\n",
    "\n",
    "# let us create the variable x and assign it an initial value\n",
    "x = torch.arange(4.0, requires_grad=True)\n",
    "print(f\"The input x: {x}\")\n",
    "\n",
    "y = f(x)\n",
    "print(f\"The output Y: {y}\")\n",
    "\n",
    "# Invoking `backward` on a non-scalar requires passing in a `gradient` argument\n",
    "# which specifies the gradient of the differentiated function w.r.t `self`.\n",
    "# In our case, we simply want to sum the partial derivatives, so passing\n",
    "# in a gradient of ones is appropriate\n",
    "y.sum().backward() # or y.backward(torch.ones(len(x))) equivalent to the below\n",
    "\n",
    "print(f\"The x grad: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6cbe6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Computing the Gradient of Python Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "138fb13a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d5a42d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -0.18225865066051483\n",
      "a grad: 819200.0\n",
      "d: -149306.28125\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "print (f\"a: {a}\")\n",
    "print (f\"a grad: {a.grad}\")\n",
    "print (f\"d: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b9333f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef8cfe",
   "metadata": {},
   "source": [
    "# Integral Calculus （积分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e073cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
